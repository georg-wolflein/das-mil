{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georg/Projects/mil/mil_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from make_summary import summarize_group\n",
    "from mil.utils import human_format\n",
    "\n",
    "yaml_folder = Path(\"conf\") / \"selected_model\" / \"mnist_collage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abmil',\n",
       " 'discrete_rel_pos_self_attention',\n",
       " 'distance_aware_self_attention',\n",
       " 'gnn_gat',\n",
       " 'gnn_gcn',\n",
       " 'induced_set_transformer',\n",
       " 'just_pool',\n",
       " 'mil_gnn',\n",
       " 'mil_gnn_ds',\n",
       " 'self_attention',\n",
       " 'self_attention_axial_pe',\n",
       " 'self_attention_fourier_pe',\n",
       " 'set_transformer',\n",
       " 'transmil']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [file.stem for file in yaml_folder.glob(\"*.yaml\") if file.name[0] != \"_\"]\n",
    "models.sort()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-05-06 23:47:36.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage-abmil\u001b[0m\n",
      "\u001b[32m2023-05-06 23:47:38.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage-discrete_rel_pos_self_attention\u001b[0m\n",
      "\u001b[32m2023-05-06 23:47:41.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage-distance_aware_self_attention\u001b[0m\n",
      "\u001b[32m2023-05-06 23:47:43.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage-gnn_gat\u001b[0m\n",
      "\u001b[32m2023-05-06 23:47:45.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage-gnn_gcn\u001b[0m\n",
      "\u001b[32m2023-05-06 23:47:47.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage-induced_set_transformer\u001b[0m\n",
      "\u001b[32m2023-05-06 23:47:50.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage-just_pool\u001b[0m\n",
      "\u001b[32m2023-05-06 23:47:52.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage-mil_gnn\u001b[0m\n",
      "\u001b[32m2023-05-06 23:47:54.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage-mil_gnn_ds\u001b[0m\n",
      "\u001b[32m2023-05-06 23:47:56.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage-self_attention\u001b[0m\n",
      "\u001b[32m2023-05-06 23:47:59.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage-self_attention_axial_pe\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:01.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage-self_attention_fourier_pe\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:04.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage-set_transformer\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:06.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage-transmil\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:08.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage_inverse-abmil\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:11.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage_inverse-discrete_rel_pos_self_attention\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:13.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage_inverse-distance_aware_self_attention\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:15.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage_inverse-gnn_gat\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:18.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage_inverse-gnn_gcn\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:20.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage_inverse-induced_set_transformer\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:22.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage_inverse-just_pool\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:24.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage_inverse-mil_gnn\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:27.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage_inverse-mil_gnn_ds\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:29.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage_inverse-self_attention\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:31.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage_inverse-self_attention_axial_pe\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:34.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage_inverse-self_attention_fourier_pe\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:36.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage_inverse-set_transformer\u001b[0m\n",
      "\u001b[32m2023-05-06 23:48:39.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmake_summary\u001b[0m:\u001b[36msummarize_group\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSummarizing group selected-mnist_collage_inverse-transmil\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mnist_collage_stats = {\n",
    "    model: summarize_group(f\"selected-mnist_collage-{model}\", log_to_wandb=False)\n",
    "    for model in models\n",
    "}\n",
    "mnist_collage_inverse_stats = {\n",
    "    model: summarize_group(f\"selected-mnist_collage_inverse-{model}\", log_to_wandb=False)\n",
    "    for model in models\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean(train/acc)</th>\n",
       "      <th>std(train/acc)</th>\n",
       "      <th>mean(train/balanced_acc)</th>\n",
       "      <th>std(train/balanced_acc)</th>\n",
       "      <th>mean(train/auc)</th>\n",
       "      <th>std(train/auc)</th>\n",
       "      <th>mean(train/f1)</th>\n",
       "      <th>std(train/f1)</th>\n",
       "      <th>mean(train/precision)</th>\n",
       "      <th>std(train/precision)</th>\n",
       "      <th>...</th>\n",
       "      <th>std(min(test/auc))</th>\n",
       "      <th>mean(min(test/f1))</th>\n",
       "      <th>std(min(test/f1))</th>\n",
       "      <th>mean(min(test/precision))</th>\n",
       "      <th>std(min(test/precision))</th>\n",
       "      <th>mean(min(test/recall))</th>\n",
       "      <th>std(min(test/recall))</th>\n",
       "      <th>mean(min(test/loss))</th>\n",
       "      <th>std(min(test/loss))</th>\n",
       "      <th>num_parameters</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">mnist_collage</th>\n",
       "      <th>abmil</th>\n",
       "      <td>0.798667</td>\n",
       "      <td>0.013864</td>\n",
       "      <td>0.798667</td>\n",
       "      <td>0.013864</td>\n",
       "      <td>0.892880</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>0.802437</td>\n",
       "      <td>0.011612</td>\n",
       "      <td>0.788393</td>\n",
       "      <td>0.021020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089262</td>\n",
       "      <td>0.122381</td>\n",
       "      <td>0.090001</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.052154</td>\n",
       "      <td>0.496041</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>16096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discrete_rel_pos_self_attention</th>\n",
       "      <td>0.921333</td>\n",
       "      <td>0.013864</td>\n",
       "      <td>0.921333</td>\n",
       "      <td>0.013864</td>\n",
       "      <td>0.969991</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.922011</td>\n",
       "      <td>0.014122</td>\n",
       "      <td>0.913741</td>\n",
       "      <td>0.014732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040614</td>\n",
       "      <td>0.282731</td>\n",
       "      <td>0.216647</td>\n",
       "      <td>0.541829</td>\n",
       "      <td>0.042952</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.235117</td>\n",
       "      <td>0.179238</td>\n",
       "      <td>0.031020</td>\n",
       "      <td>17769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance_aware_self_attention</th>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.028829</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.028829</td>\n",
       "      <td>0.977147</td>\n",
       "      <td>0.013009</td>\n",
       "      <td>0.931809</td>\n",
       "      <td>0.029327</td>\n",
       "      <td>0.933033</td>\n",
       "      <td>0.026098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132860</td>\n",
       "      <td>0.268339</td>\n",
       "      <td>0.301498</td>\n",
       "      <td>0.381370</td>\n",
       "      <td>0.217762</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.261687</td>\n",
       "      <td>0.105759</td>\n",
       "      <td>0.039776</td>\n",
       "      <td>17355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gnn_gat</th>\n",
       "      <td>0.810667</td>\n",
       "      <td>0.089362</td>\n",
       "      <td>0.810667</td>\n",
       "      <td>0.089362</td>\n",
       "      <td>0.873431</td>\n",
       "      <td>0.085859</td>\n",
       "      <td>0.832326</td>\n",
       "      <td>0.068101</td>\n",
       "      <td>0.771709</td>\n",
       "      <td>0.113700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161456</td>\n",
       "      <td>0.255457</td>\n",
       "      <td>0.350124</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.273861</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.322676</td>\n",
       "      <td>0.441132</td>\n",
       "      <td>0.068110</td>\n",
       "      <td>16733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gnn_gcn</th>\n",
       "      <td>0.864667</td>\n",
       "      <td>0.030876</td>\n",
       "      <td>0.864667</td>\n",
       "      <td>0.030876</td>\n",
       "      <td>0.932364</td>\n",
       "      <td>0.029260</td>\n",
       "      <td>0.870508</td>\n",
       "      <td>0.026021</td>\n",
       "      <td>0.839199</td>\n",
       "      <td>0.046225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124634</td>\n",
       "      <td>0.347917</td>\n",
       "      <td>0.334925</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.273861</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.311127</td>\n",
       "      <td>0.429991</td>\n",
       "      <td>0.063101</td>\n",
       "      <td>16303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>induced_set_transformer</th>\n",
       "      <td>0.812667</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>0.812667</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>0.888684</td>\n",
       "      <td>0.008490</td>\n",
       "      <td>0.818641</td>\n",
       "      <td>0.015595</td>\n",
       "      <td>0.793712</td>\n",
       "      <td>0.019442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496567</td>\n",
       "      <td>0.014609</td>\n",
       "      <td>22108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just_pool</th>\n",
       "      <td>0.846000</td>\n",
       "      <td>0.021266</td>\n",
       "      <td>0.846000</td>\n",
       "      <td>0.021266</td>\n",
       "      <td>0.924356</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.848498</td>\n",
       "      <td>0.019381</td>\n",
       "      <td>0.836321</td>\n",
       "      <td>0.029678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095424</td>\n",
       "      <td>0.302742</td>\n",
       "      <td>0.342149</td>\n",
       "      <td>0.303245</td>\n",
       "      <td>0.277000</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.413183</td>\n",
       "      <td>0.396384</td>\n",
       "      <td>0.012937</td>\n",
       "      <td>15585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mil_gnn</th>\n",
       "      <td>0.546000</td>\n",
       "      <td>0.060892</td>\n",
       "      <td>0.546000</td>\n",
       "      <td>0.060892</td>\n",
       "      <td>0.648053</td>\n",
       "      <td>0.021657</td>\n",
       "      <td>0.243578</td>\n",
       "      <td>0.280517</td>\n",
       "      <td>0.496576</td>\n",
       "      <td>0.292709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.679137</td>\n",
       "      <td>0.012082</td>\n",
       "      <td>19198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mil_gnn_ds</th>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.143225</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.143225</td>\n",
       "      <td>0.770738</td>\n",
       "      <td>0.129555</td>\n",
       "      <td>0.522335</td>\n",
       "      <td>0.361646</td>\n",
       "      <td>0.673112</td>\n",
       "      <td>0.381762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577253</td>\n",
       "      <td>0.095678</td>\n",
       "      <td>19198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attention</th>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.041001</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.041001</td>\n",
       "      <td>0.944827</td>\n",
       "      <td>0.035152</td>\n",
       "      <td>0.883701</td>\n",
       "      <td>0.038384</td>\n",
       "      <td>0.876418</td>\n",
       "      <td>0.054361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064776</td>\n",
       "      <td>0.078788</td>\n",
       "      <td>0.176175</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.116276</td>\n",
       "      <td>0.414764</td>\n",
       "      <td>0.051002</td>\n",
       "      <td>17569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attention_axial_pe</th>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>0.941067</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>0.862728</td>\n",
       "      <td>0.009437</td>\n",
       "      <td>0.857770</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042844</td>\n",
       "      <td>0.193673</td>\n",
       "      <td>0.171340</td>\n",
       "      <td>0.415276</td>\n",
       "      <td>0.232496</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.117813</td>\n",
       "      <td>0.453008</td>\n",
       "      <td>0.087123</td>\n",
       "      <td>17569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attention_fourier_pe</th>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.034529</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.034529</td>\n",
       "      <td>0.943498</td>\n",
       "      <td>0.025279</td>\n",
       "      <td>0.882988</td>\n",
       "      <td>0.032065</td>\n",
       "      <td>0.851577</td>\n",
       "      <td>0.044510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071892</td>\n",
       "      <td>0.277011</td>\n",
       "      <td>0.309082</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.273861</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.247629</td>\n",
       "      <td>0.364992</td>\n",
       "      <td>0.049122</td>\n",
       "      <td>18401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set_transformer</th>\n",
       "      <td>0.815333</td>\n",
       "      <td>0.051779</td>\n",
       "      <td>0.815333</td>\n",
       "      <td>0.051779</td>\n",
       "      <td>0.868987</td>\n",
       "      <td>0.064114</td>\n",
       "      <td>0.831547</td>\n",
       "      <td>0.041560</td>\n",
       "      <td>0.769880</td>\n",
       "      <td>0.057028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104439</td>\n",
       "      <td>0.117333</td>\n",
       "      <td>0.262365</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.196774</td>\n",
       "      <td>0.380260</td>\n",
       "      <td>0.075452</td>\n",
       "      <td>17553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transmil</th>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.029477</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.029477</td>\n",
       "      <td>0.990809</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.957548</td>\n",
       "      <td>0.029249</td>\n",
       "      <td>0.953845</td>\n",
       "      <td>0.031336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515279</td>\n",
       "      <td>0.045246</td>\n",
       "      <td>2179281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">mnist_collage_inverse</th>\n",
       "      <th>abmil</th>\n",
       "      <td>0.804667</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>0.804667</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>0.889573</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0.810792</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.786974</td>\n",
       "      <td>0.020440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077874</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.167705</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.107331</td>\n",
       "      <td>0.492362</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>16096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discrete_rel_pos_self_attention</th>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.031127</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.031127</td>\n",
       "      <td>0.953520</td>\n",
       "      <td>0.030899</td>\n",
       "      <td>0.877635</td>\n",
       "      <td>0.027632</td>\n",
       "      <td>0.880253</td>\n",
       "      <td>0.046654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071188</td>\n",
       "      <td>0.197187</td>\n",
       "      <td>0.147955</td>\n",
       "      <td>0.391557</td>\n",
       "      <td>0.222618</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.100598</td>\n",
       "      <td>0.288473</td>\n",
       "      <td>0.120389</td>\n",
       "      <td>17769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance_aware_self_attention</th>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.048362</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.048362</td>\n",
       "      <td>0.964933</td>\n",
       "      <td>0.035930</td>\n",
       "      <td>0.913063</td>\n",
       "      <td>0.044053</td>\n",
       "      <td>0.891848</td>\n",
       "      <td>0.060053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086871</td>\n",
       "      <td>0.083582</td>\n",
       "      <td>0.186895</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.125220</td>\n",
       "      <td>0.201749</td>\n",
       "      <td>0.141451</td>\n",
       "      <td>17355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gnn_gat</th>\n",
       "      <td>0.744667</td>\n",
       "      <td>0.033383</td>\n",
       "      <td>0.744667</td>\n",
       "      <td>0.033383</td>\n",
       "      <td>0.795351</td>\n",
       "      <td>0.044686</td>\n",
       "      <td>0.780069</td>\n",
       "      <td>0.027318</td>\n",
       "      <td>0.686160</td>\n",
       "      <td>0.031816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157508</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.069877</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.159719</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>0.495316</td>\n",
       "      <td>0.009344</td>\n",
       "      <td>16733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gnn_gcn</th>\n",
       "      <td>0.882667</td>\n",
       "      <td>0.033780</td>\n",
       "      <td>0.882667</td>\n",
       "      <td>0.033780</td>\n",
       "      <td>0.940907</td>\n",
       "      <td>0.026753</td>\n",
       "      <td>0.886254</td>\n",
       "      <td>0.030535</td>\n",
       "      <td>0.863663</td>\n",
       "      <td>0.043182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118964</td>\n",
       "      <td>0.087843</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.289742</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.393801</td>\n",
       "      <td>0.028638</td>\n",
       "      <td>16303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>induced_set_transformer</th>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.022730</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.022730</td>\n",
       "      <td>0.881316</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.021502</td>\n",
       "      <td>0.783269</td>\n",
       "      <td>0.021618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501810</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>22108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just_pool</th>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.009129</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.009129</td>\n",
       "      <td>0.912267</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>0.843970</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.824249</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083999</td>\n",
       "      <td>0.321817</td>\n",
       "      <td>0.327431</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.445960</td>\n",
       "      <td>0.479325</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>15585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mil_gnn</th>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.095406</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.095406</td>\n",
       "      <td>0.722529</td>\n",
       "      <td>0.056187</td>\n",
       "      <td>0.144913</td>\n",
       "      <td>0.316732</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.341734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674320</td>\n",
       "      <td>0.032640</td>\n",
       "      <td>19198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mil_gnn_ds</th>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.022779</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.022779</td>\n",
       "      <td>0.864044</td>\n",
       "      <td>0.027121</td>\n",
       "      <td>0.772167</td>\n",
       "      <td>0.020869</td>\n",
       "      <td>0.821109</td>\n",
       "      <td>0.052296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516723</td>\n",
       "      <td>0.022650</td>\n",
       "      <td>19198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attention</th>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.059133</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.059133</td>\n",
       "      <td>0.933111</td>\n",
       "      <td>0.063079</td>\n",
       "      <td>0.880792</td>\n",
       "      <td>0.051686</td>\n",
       "      <td>0.860176</td>\n",
       "      <td>0.075147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063190</td>\n",
       "      <td>0.198788</td>\n",
       "      <td>0.281782</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.273861</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.240416</td>\n",
       "      <td>0.453589</td>\n",
       "      <td>0.037011</td>\n",
       "      <td>17569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attention_axial_pe</th>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.017575</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.017575</td>\n",
       "      <td>0.962836</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.902839</td>\n",
       "      <td>0.018517</td>\n",
       "      <td>0.894369</td>\n",
       "      <td>0.018210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034096</td>\n",
       "      <td>0.320087</td>\n",
       "      <td>0.257018</td>\n",
       "      <td>0.421016</td>\n",
       "      <td>0.235715</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.245601</td>\n",
       "      <td>0.407073</td>\n",
       "      <td>0.024743</td>\n",
       "      <td>17569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attention_fourier_pe</th>\n",
       "      <td>0.878667</td>\n",
       "      <td>0.037312</td>\n",
       "      <td>0.878667</td>\n",
       "      <td>0.037312</td>\n",
       "      <td>0.938702</td>\n",
       "      <td>0.033547</td>\n",
       "      <td>0.882928</td>\n",
       "      <td>0.034547</td>\n",
       "      <td>0.855908</td>\n",
       "      <td>0.043708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139499</td>\n",
       "      <td>0.221461</td>\n",
       "      <td>0.237936</td>\n",
       "      <td>0.406383</td>\n",
       "      <td>0.227595</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.184608</td>\n",
       "      <td>0.398939</td>\n",
       "      <td>0.021093</td>\n",
       "      <td>18401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set_transformer</th>\n",
       "      <td>0.818667</td>\n",
       "      <td>0.017733</td>\n",
       "      <td>0.818667</td>\n",
       "      <td>0.017733</td>\n",
       "      <td>0.871973</td>\n",
       "      <td>0.013515</td>\n",
       "      <td>0.832559</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>0.772771</td>\n",
       "      <td>0.011419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407280</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>17553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transmil</th>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.014530</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.014530</td>\n",
       "      <td>0.992747</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.956935</td>\n",
       "      <td>0.014425</td>\n",
       "      <td>0.951388</td>\n",
       "      <td>0.017197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033491</td>\n",
       "      <td>0.070941</td>\n",
       "      <td>0.108471</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.273861</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.061644</td>\n",
       "      <td>0.503298</td>\n",
       "      <td>0.046186</td>\n",
       "      <td>2179281.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       mean(train/acc)  \\\n",
       "dataset               model                                              \n",
       "mnist_collage         abmil                                   0.798667   \n",
       "                      discrete_rel_pos_self_attention         0.921333   \n",
       "                      distance_aware_self_attention           0.932000   \n",
       "                      gnn_gat                                 0.810667   \n",
       "                      gnn_gcn                                 0.864667   \n",
       "                      induced_set_transformer                 0.812667   \n",
       "                      just_pool                               0.846000   \n",
       "                      mil_gnn                                 0.546000   \n",
       "                      mil_gnn_ds                              0.686000   \n",
       "                      self_attention                          0.882000   \n",
       "                      self_attention_axial_pe                 0.862000   \n",
       "                      self_attention_fourier_pe               0.878000   \n",
       "                      set_transformer                         0.815333   \n",
       "                      transmil                                0.957333   \n",
       "mnist_collage_inverse abmil                                   0.804667   \n",
       "                      discrete_rel_pos_self_attention         0.877333   \n",
       "                      distance_aware_self_attention           0.910000   \n",
       "                      gnn_gat                                 0.744667   \n",
       "                      gnn_gcn                                 0.882667   \n",
       "                      induced_set_transformer                 0.813333   \n",
       "                      just_pool                               0.840000   \n",
       "                      mil_gnn                                 0.542667   \n",
       "                      mil_gnn_ds                              0.784000   \n",
       "                      self_attention                          0.876000   \n",
       "                      self_attention_axial_pe                 0.902000   \n",
       "                      self_attention_fourier_pe               0.878667   \n",
       "                      set_transformer                         0.818667   \n",
       "                      transmil                                0.956667   \n",
       "\n",
       "                                                       std(train/acc)  \\\n",
       "dataset               model                                             \n",
       "mnist_collage         abmil                                  0.013864   \n",
       "                      discrete_rel_pos_self_attention        0.013864   \n",
       "                      distance_aware_self_attention          0.028829   \n",
       "                      gnn_gat                                0.089362   \n",
       "                      gnn_gcn                                0.030876   \n",
       "                      induced_set_transformer                0.016898   \n",
       "                      just_pool                              0.021266   \n",
       "                      mil_gnn                                0.060892   \n",
       "                      mil_gnn_ds                             0.143225   \n",
       "                      self_attention                         0.041001   \n",
       "                      self_attention_axial_pe                0.007674   \n",
       "                      self_attention_fourier_pe              0.034529   \n",
       "                      set_transformer                        0.051779   \n",
       "                      transmil                               0.029477   \n",
       "mnist_collage_inverse abmil                                  0.006055   \n",
       "                      discrete_rel_pos_self_attention        0.031127   \n",
       "                      distance_aware_self_attention          0.048362   \n",
       "                      gnn_gat                                0.033383   \n",
       "                      gnn_gcn                                0.033780   \n",
       "                      induced_set_transformer                0.022730   \n",
       "                      just_pool                              0.009129   \n",
       "                      mil_gnn                                0.095406   \n",
       "                      mil_gnn_ds                             0.022779   \n",
       "                      self_attention                         0.059133   \n",
       "                      self_attention_axial_pe                0.017575   \n",
       "                      self_attention_fourier_pe              0.037312   \n",
       "                      set_transformer                        0.017733   \n",
       "                      transmil                               0.014530   \n",
       "\n",
       "                                                       mean(train/balanced_acc)  \\\n",
       "dataset               model                                                       \n",
       "mnist_collage         abmil                                            0.798667   \n",
       "                      discrete_rel_pos_self_attention                  0.921333   \n",
       "                      distance_aware_self_attention                    0.932000   \n",
       "                      gnn_gat                                          0.810667   \n",
       "                      gnn_gcn                                          0.864667   \n",
       "                      induced_set_transformer                          0.812667   \n",
       "                      just_pool                                        0.846000   \n",
       "                      mil_gnn                                          0.546000   \n",
       "                      mil_gnn_ds                                       0.686000   \n",
       "                      self_attention                                   0.882000   \n",
       "                      self_attention_axial_pe                          0.862000   \n",
       "                      self_attention_fourier_pe                        0.878000   \n",
       "                      set_transformer                                  0.815333   \n",
       "                      transmil                                         0.957333   \n",
       "mnist_collage_inverse abmil                                            0.804667   \n",
       "                      discrete_rel_pos_self_attention                  0.877333   \n",
       "                      distance_aware_self_attention                    0.910000   \n",
       "                      gnn_gat                                          0.744667   \n",
       "                      gnn_gcn                                          0.882667   \n",
       "                      induced_set_transformer                          0.813333   \n",
       "                      just_pool                                        0.840000   \n",
       "                      mil_gnn                                          0.542667   \n",
       "                      mil_gnn_ds                                       0.784000   \n",
       "                      self_attention                                   0.876000   \n",
       "                      self_attention_axial_pe                          0.902000   \n",
       "                      self_attention_fourier_pe                        0.878667   \n",
       "                      set_transformer                                  0.818667   \n",
       "                      transmil                                         0.956667   \n",
       "\n",
       "                                                       std(train/balanced_acc)  \\\n",
       "dataset               model                                                      \n",
       "mnist_collage         abmil                                           0.013864   \n",
       "                      discrete_rel_pos_self_attention                 0.013864   \n",
       "                      distance_aware_self_attention                   0.028829   \n",
       "                      gnn_gat                                         0.089362   \n",
       "                      gnn_gcn                                         0.030876   \n",
       "                      induced_set_transformer                         0.016898   \n",
       "                      just_pool                                       0.021266   \n",
       "                      mil_gnn                                         0.060892   \n",
       "                      mil_gnn_ds                                      0.143225   \n",
       "                      self_attention                                  0.041001   \n",
       "                      self_attention_axial_pe                         0.007674   \n",
       "                      self_attention_fourier_pe                       0.034529   \n",
       "                      set_transformer                                 0.051779   \n",
       "                      transmil                                        0.029477   \n",
       "mnist_collage_inverse abmil                                           0.006055   \n",
       "                      discrete_rel_pos_self_attention                 0.031127   \n",
       "                      distance_aware_self_attention                   0.048362   \n",
       "                      gnn_gat                                         0.033383   \n",
       "                      gnn_gcn                                         0.033780   \n",
       "                      induced_set_transformer                         0.022730   \n",
       "                      just_pool                                       0.009129   \n",
       "                      mil_gnn                                         0.095406   \n",
       "                      mil_gnn_ds                                      0.022779   \n",
       "                      self_attention                                  0.059133   \n",
       "                      self_attention_axial_pe                         0.017575   \n",
       "                      self_attention_fourier_pe                       0.037312   \n",
       "                      set_transformer                                 0.017733   \n",
       "                      transmil                                        0.014530   \n",
       "\n",
       "                                                       mean(train/auc)  \\\n",
       "dataset               model                                              \n",
       "mnist_collage         abmil                                   0.892880   \n",
       "                      discrete_rel_pos_self_attention         0.969991   \n",
       "                      distance_aware_self_attention           0.977147   \n",
       "                      gnn_gat                                 0.873431   \n",
       "                      gnn_gcn                                 0.932364   \n",
       "                      induced_set_transformer                 0.888684   \n",
       "                      just_pool                               0.924356   \n",
       "                      mil_gnn                                 0.648053   \n",
       "                      mil_gnn_ds                              0.770738   \n",
       "                      self_attention                          0.944827   \n",
       "                      self_attention_axial_pe                 0.941067   \n",
       "                      self_attention_fourier_pe               0.943498   \n",
       "                      set_transformer                         0.868987   \n",
       "                      transmil                                0.990809   \n",
       "mnist_collage_inverse abmil                                   0.889573   \n",
       "                      discrete_rel_pos_self_attention         0.953520   \n",
       "                      distance_aware_self_attention           0.964933   \n",
       "                      gnn_gat                                 0.795351   \n",
       "                      gnn_gcn                                 0.940907   \n",
       "                      induced_set_transformer                 0.881316   \n",
       "                      just_pool                               0.912267   \n",
       "                      mil_gnn                                 0.722529   \n",
       "                      mil_gnn_ds                              0.864044   \n",
       "                      self_attention                          0.933111   \n",
       "                      self_attention_axial_pe                 0.962836   \n",
       "                      self_attention_fourier_pe               0.938702   \n",
       "                      set_transformer                         0.871973   \n",
       "                      transmil                                0.992747   \n",
       "\n",
       "                                                       std(train/auc)  \\\n",
       "dataset               model                                             \n",
       "mnist_collage         abmil                                  0.016511   \n",
       "                      discrete_rel_pos_self_attention        0.005166   \n",
       "                      distance_aware_self_attention          0.013009   \n",
       "                      gnn_gat                                0.085859   \n",
       "                      gnn_gcn                                0.029260   \n",
       "                      induced_set_transformer                0.008490   \n",
       "                      just_pool                              0.007208   \n",
       "                      mil_gnn                                0.021657   \n",
       "                      mil_gnn_ds                             0.129555   \n",
       "                      self_attention                         0.035152   \n",
       "                      self_attention_axial_pe                0.010791   \n",
       "                      self_attention_fourier_pe              0.025279   \n",
       "                      set_transformer                        0.064114   \n",
       "                      transmil                               0.008832   \n",
       "mnist_collage_inverse abmil                                  0.011657   \n",
       "                      discrete_rel_pos_self_attention        0.030899   \n",
       "                      distance_aware_self_attention          0.035930   \n",
       "                      gnn_gat                                0.044686   \n",
       "                      gnn_gcn                                0.026753   \n",
       "                      induced_set_transformer                0.011177   \n",
       "                      just_pool                              0.008215   \n",
       "                      mil_gnn                                0.056187   \n",
       "                      mil_gnn_ds                             0.027121   \n",
       "                      self_attention                         0.063079   \n",
       "                      self_attention_axial_pe                0.005261   \n",
       "                      self_attention_fourier_pe              0.033547   \n",
       "                      set_transformer                        0.013515   \n",
       "                      transmil                               0.003637   \n",
       "\n",
       "                                                       mean(train/f1)  \\\n",
       "dataset               model                                             \n",
       "mnist_collage         abmil                                  0.802437   \n",
       "                      discrete_rel_pos_self_attention        0.922011   \n",
       "                      distance_aware_self_attention          0.931809   \n",
       "                      gnn_gat                                0.832326   \n",
       "                      gnn_gcn                                0.870508   \n",
       "                      induced_set_transformer                0.818641   \n",
       "                      just_pool                              0.848498   \n",
       "                      mil_gnn                                0.243578   \n",
       "                      mil_gnn_ds                             0.522335   \n",
       "                      self_attention                         0.883701   \n",
       "                      self_attention_axial_pe                0.862728   \n",
       "                      self_attention_fourier_pe              0.882988   \n",
       "                      set_transformer                        0.831547   \n",
       "                      transmil                               0.957548   \n",
       "mnist_collage_inverse abmil                                  0.810792   \n",
       "                      discrete_rel_pos_self_attention        0.877635   \n",
       "                      distance_aware_self_attention          0.913063   \n",
       "                      gnn_gat                                0.780069   \n",
       "                      gnn_gcn                                0.886254   \n",
       "                      induced_set_transformer                0.822775   \n",
       "                      just_pool                              0.843970   \n",
       "                      mil_gnn                                0.144913   \n",
       "                      mil_gnn_ds                             0.772167   \n",
       "                      self_attention                         0.880792   \n",
       "                      self_attention_axial_pe                0.902839   \n",
       "                      self_attention_fourier_pe              0.882928   \n",
       "                      set_transformer                        0.832559   \n",
       "                      transmil                               0.956935   \n",
       "\n",
       "                                                       std(train/f1)  \\\n",
       "dataset               model                                            \n",
       "mnist_collage         abmil                                 0.011612   \n",
       "                      discrete_rel_pos_self_attention       0.014122   \n",
       "                      distance_aware_self_attention         0.029327   \n",
       "                      gnn_gat                               0.068101   \n",
       "                      gnn_gcn                               0.026021   \n",
       "                      induced_set_transformer               0.015595   \n",
       "                      just_pool                             0.019381   \n",
       "                      mil_gnn                               0.280517   \n",
       "                      mil_gnn_ds                            0.361646   \n",
       "                      self_attention                        0.038384   \n",
       "                      self_attention_axial_pe               0.009437   \n",
       "                      self_attention_fourier_pe             0.032065   \n",
       "                      set_transformer                       0.041560   \n",
       "                      transmil                              0.029249   \n",
       "mnist_collage_inverse abmil                                 0.004914   \n",
       "                      discrete_rel_pos_self_attention       0.027632   \n",
       "                      distance_aware_self_attention         0.044053   \n",
       "                      gnn_gat                               0.027318   \n",
       "                      gnn_gcn                               0.030535   \n",
       "                      induced_set_transformer               0.021502   \n",
       "                      just_pool                             0.007820   \n",
       "                      mil_gnn                               0.316732   \n",
       "                      mil_gnn_ds                            0.020869   \n",
       "                      self_attention                        0.051686   \n",
       "                      self_attention_axial_pe               0.018517   \n",
       "                      self_attention_fourier_pe             0.034547   \n",
       "                      set_transformer                       0.018108   \n",
       "                      transmil                              0.014425   \n",
       "\n",
       "                                                       mean(train/precision)  \\\n",
       "dataset               model                                                    \n",
       "mnist_collage         abmil                                         0.788393   \n",
       "                      discrete_rel_pos_self_attention               0.913741   \n",
       "                      distance_aware_self_attention                 0.933033   \n",
       "                      gnn_gat                                       0.771709   \n",
       "                      gnn_gcn                                       0.839199   \n",
       "                      induced_set_transformer                       0.793712   \n",
       "                      just_pool                                     0.836321   \n",
       "                      mil_gnn                                       0.496576   \n",
       "                      mil_gnn_ds                                    0.673112   \n",
       "                      self_attention                                0.876418   \n",
       "                      self_attention_axial_pe                       0.857770   \n",
       "                      self_attention_fourier_pe                     0.851577   \n",
       "                      set_transformer                               0.769880   \n",
       "                      transmil                                      0.953845   \n",
       "mnist_collage_inverse abmil                                         0.786974   \n",
       "                      discrete_rel_pos_self_attention               0.880253   \n",
       "                      distance_aware_self_attention                 0.891848   \n",
       "                      gnn_gat                                       0.686160   \n",
       "                      gnn_gcn                                       0.863663   \n",
       "                      induced_set_transformer                       0.783269   \n",
       "                      just_pool                                     0.824249   \n",
       "                      mil_gnn                                       0.243243   \n",
       "                      mil_gnn_ds                                    0.821109   \n",
       "                      self_attention                                0.860176   \n",
       "                      self_attention_axial_pe                       0.894369   \n",
       "                      self_attention_fourier_pe                     0.855908   \n",
       "                      set_transformer                               0.772771   \n",
       "                      transmil                                      0.951388   \n",
       "\n",
       "                                                       std(train/precision)  \\\n",
       "dataset               model                                                   \n",
       "mnist_collage         abmil                                        0.021020   \n",
       "                      discrete_rel_pos_self_attention              0.014732   \n",
       "                      distance_aware_self_attention                0.026098   \n",
       "                      gnn_gat                                      0.113700   \n",
       "                      gnn_gcn                                      0.046225   \n",
       "                      induced_set_transformer                      0.019442   \n",
       "                      just_pool                                    0.029678   \n",
       "                      mil_gnn                                      0.292709   \n",
       "                      mil_gnn_ds                                   0.381762   \n",
       "                      self_attention                               0.054361   \n",
       "                      self_attention_axial_pe                      0.004454   \n",
       "                      self_attention_fourier_pe                    0.044510   \n",
       "                      set_transformer                              0.057028   \n",
       "                      transmil                                     0.031336   \n",
       "mnist_collage_inverse abmil                                        0.020440   \n",
       "                      discrete_rel_pos_self_attention              0.046654   \n",
       "                      distance_aware_self_attention                0.060053   \n",
       "                      gnn_gat                                      0.031816   \n",
       "                      gnn_gcn                                      0.043182   \n",
       "                      induced_set_transformer                      0.021618   \n",
       "                      just_pool                                    0.019802   \n",
       "                      mil_gnn                                      0.341734   \n",
       "                      mil_gnn_ds                                   0.052296   \n",
       "                      self_attention                               0.075147   \n",
       "                      self_attention_axial_pe                      0.018210   \n",
       "                      self_attention_fourier_pe                    0.043708   \n",
       "                      set_transformer                              0.011419   \n",
       "                      transmil                                     0.017197   \n",
       "\n",
       "                                                       ...  \\\n",
       "dataset               model                            ...   \n",
       "mnist_collage         abmil                            ...   \n",
       "                      discrete_rel_pos_self_attention  ...   \n",
       "                      distance_aware_self_attention    ...   \n",
       "                      gnn_gat                          ...   \n",
       "                      gnn_gcn                          ...   \n",
       "                      induced_set_transformer          ...   \n",
       "                      just_pool                        ...   \n",
       "                      mil_gnn                          ...   \n",
       "                      mil_gnn_ds                       ...   \n",
       "                      self_attention                   ...   \n",
       "                      self_attention_axial_pe          ...   \n",
       "                      self_attention_fourier_pe        ...   \n",
       "                      set_transformer                  ...   \n",
       "                      transmil                         ...   \n",
       "mnist_collage_inverse abmil                            ...   \n",
       "                      discrete_rel_pos_self_attention  ...   \n",
       "                      distance_aware_self_attention    ...   \n",
       "                      gnn_gat                          ...   \n",
       "                      gnn_gcn                          ...   \n",
       "                      induced_set_transformer          ...   \n",
       "                      just_pool                        ...   \n",
       "                      mil_gnn                          ...   \n",
       "                      mil_gnn_ds                       ...   \n",
       "                      self_attention                   ...   \n",
       "                      self_attention_axial_pe          ...   \n",
       "                      self_attention_fourier_pe        ...   \n",
       "                      set_transformer                  ...   \n",
       "                      transmil                         ...   \n",
       "\n",
       "                                                       std(min(test/auc))  \\\n",
       "dataset               model                                                 \n",
       "mnist_collage         abmil                                      0.089262   \n",
       "                      discrete_rel_pos_self_attention            0.040614   \n",
       "                      distance_aware_self_attention              0.132860   \n",
       "                      gnn_gat                                    0.161456   \n",
       "                      gnn_gcn                                    0.124634   \n",
       "                      induced_set_transformer                    0.098161   \n",
       "                      just_pool                                  0.095424   \n",
       "                      mil_gnn                                    0.031390   \n",
       "                      mil_gnn_ds                                 0.101038   \n",
       "                      self_attention                             0.064776   \n",
       "                      self_attention_axial_pe                    0.042844   \n",
       "                      self_attention_fourier_pe                  0.071892   \n",
       "                      set_transformer                            0.104439   \n",
       "                      transmil                                   0.038421   \n",
       "mnist_collage_inverse abmil                                      0.077874   \n",
       "                      discrete_rel_pos_self_attention            0.071188   \n",
       "                      distance_aware_self_attention              0.086871   \n",
       "                      gnn_gat                                    0.157508   \n",
       "                      gnn_gcn                                    0.118964   \n",
       "                      induced_set_transformer                    0.080341   \n",
       "                      just_pool                                  0.083999   \n",
       "                      mil_gnn                                    0.029870   \n",
       "                      mil_gnn_ds                                 0.002606   \n",
       "                      self_attention                             0.063190   \n",
       "                      self_attention_axial_pe                    0.034096   \n",
       "                      self_attention_fourier_pe                  0.139499   \n",
       "                      set_transformer                            0.143815   \n",
       "                      transmil                                   0.033491   \n",
       "\n",
       "                                                       mean(min(test/f1))  \\\n",
       "dataset               model                                                 \n",
       "mnist_collage         abmil                                      0.122381   \n",
       "                      discrete_rel_pos_self_attention            0.282731   \n",
       "                      distance_aware_self_attention              0.268339   \n",
       "                      gnn_gat                                    0.255457   \n",
       "                      gnn_gcn                                    0.347917   \n",
       "                      induced_set_transformer                    0.000000   \n",
       "                      just_pool                                  0.302742   \n",
       "                      mil_gnn                                    0.000000   \n",
       "                      mil_gnn_ds                                 0.000000   \n",
       "                      self_attention                             0.078788   \n",
       "                      self_attention_axial_pe                    0.193673   \n",
       "                      self_attention_fourier_pe                  0.277011   \n",
       "                      set_transformer                            0.117333   \n",
       "                      transmil                                   0.000000   \n",
       "mnist_collage_inverse abmil                                      0.075000   \n",
       "                      discrete_rel_pos_self_attention            0.197187   \n",
       "                      distance_aware_self_attention              0.083582   \n",
       "                      gnn_gat                                    0.031250   \n",
       "                      gnn_gcn                                    0.087843   \n",
       "                      induced_set_transformer                    0.000000   \n",
       "                      just_pool                                  0.321817   \n",
       "                      mil_gnn                                    0.000000   \n",
       "                      mil_gnn_ds                                 0.000000   \n",
       "                      self_attention                             0.198788   \n",
       "                      self_attention_axial_pe                    0.320087   \n",
       "                      self_attention_fourier_pe                  0.221461   \n",
       "                      set_transformer                            0.000000   \n",
       "                      transmil                                   0.070941   \n",
       "\n",
       "                                                       std(min(test/f1))  \\\n",
       "dataset               model                                                \n",
       "mnist_collage         abmil                                     0.090001   \n",
       "                      discrete_rel_pos_self_attention           0.216647   \n",
       "                      distance_aware_self_attention             0.301498   \n",
       "                      gnn_gat                                   0.350124   \n",
       "                      gnn_gcn                                   0.334925   \n",
       "                      induced_set_transformer                   0.000000   \n",
       "                      just_pool                                 0.342149   \n",
       "                      mil_gnn                                   0.000000   \n",
       "                      mil_gnn_ds                                0.000000   \n",
       "                      self_attention                            0.176175   \n",
       "                      self_attention_axial_pe                   0.171340   \n",
       "                      self_attention_fourier_pe                 0.309082   \n",
       "                      set_transformer                           0.262365   \n",
       "                      transmil                                  0.000000   \n",
       "mnist_collage_inverse abmil                                     0.167705   \n",
       "                      discrete_rel_pos_self_attention           0.147955   \n",
       "                      distance_aware_self_attention             0.186895   \n",
       "                      gnn_gat                                   0.069877   \n",
       "                      gnn_gcn                                   0.175325   \n",
       "                      induced_set_transformer                   0.000000   \n",
       "                      just_pool                                 0.327431   \n",
       "                      mil_gnn                                   0.000000   \n",
       "                      mil_gnn_ds                                0.000000   \n",
       "                      self_attention                            0.281782   \n",
       "                      self_attention_axial_pe                   0.257018   \n",
       "                      self_attention_fourier_pe                 0.237936   \n",
       "                      set_transformer                           0.000000   \n",
       "                      transmil                                  0.108471   \n",
       "\n",
       "                                                       mean(min(test/precision))  \\\n",
       "dataset               model                                                        \n",
       "mnist_collage         abmil                                             0.400000   \n",
       "                      discrete_rel_pos_self_attention                   0.541829   \n",
       "                      distance_aware_self_attention                     0.381370   \n",
       "                      gnn_gat                                           0.200000   \n",
       "                      gnn_gcn                                           0.300000   \n",
       "                      induced_set_transformer                           0.000000   \n",
       "                      just_pool                                         0.303245   \n",
       "                      mil_gnn                                           0.000000   \n",
       "                      mil_gnn_ds                                        0.000000   \n",
       "                      self_attention                                    0.100000   \n",
       "                      self_attention_axial_pe                           0.415276   \n",
       "                      self_attention_fourier_pe                         0.300000   \n",
       "                      set_transformer                                   0.100000   \n",
       "                      transmil                                          0.000000   \n",
       "mnist_collage_inverse abmil                                             0.100000   \n",
       "                      discrete_rel_pos_self_attention                   0.391557   \n",
       "                      distance_aware_self_attention                     0.100000   \n",
       "                      gnn_gat                                           0.071429   \n",
       "                      gnn_gcn                                           0.211111   \n",
       "                      induced_set_transformer                           0.000000   \n",
       "                      just_pool                                         0.400000   \n",
       "                      mil_gnn                                           0.000000   \n",
       "                      mil_gnn_ds                                        0.000000   \n",
       "                      self_attention                                    0.200000   \n",
       "                      self_attention_axial_pe                           0.421016   \n",
       "                      self_attention_fourier_pe                         0.406383   \n",
       "                      set_transformer                                   0.000000   \n",
       "                      transmil                                          0.200000   \n",
       "\n",
       "                                                       std(min(test/precision))  \\\n",
       "dataset               model                                                       \n",
       "mnist_collage         abmil                                            0.223607   \n",
       "                      discrete_rel_pos_self_attention                  0.042952   \n",
       "                      distance_aware_self_attention                    0.217762   \n",
       "                      gnn_gat                                          0.273861   \n",
       "                      gnn_gcn                                          0.273861   \n",
       "                      induced_set_transformer                          0.000000   \n",
       "                      just_pool                                        0.277000   \n",
       "                      mil_gnn                                          0.000000   \n",
       "                      mil_gnn_ds                                       0.000000   \n",
       "                      self_attention                                   0.223607   \n",
       "                      self_attention_axial_pe                          0.232496   \n",
       "                      self_attention_fourier_pe                        0.273861   \n",
       "                      set_transformer                                  0.223607   \n",
       "                      transmil                                         0.000000   \n",
       "mnist_collage_inverse abmil                                            0.223607   \n",
       "                      discrete_rel_pos_self_attention                  0.222618   \n",
       "                      distance_aware_self_attention                    0.223607   \n",
       "                      gnn_gat                                          0.159719   \n",
       "                      gnn_gcn                                          0.289742   \n",
       "                      induced_set_transformer                          0.000000   \n",
       "                      just_pool                                        0.223607   \n",
       "                      mil_gnn                                          0.000000   \n",
       "                      mil_gnn_ds                                       0.000000   \n",
       "                      self_attention                                   0.273861   \n",
       "                      self_attention_axial_pe                          0.235715   \n",
       "                      self_attention_fourier_pe                        0.227595   \n",
       "                      set_transformer                                  0.000000   \n",
       "                      transmil                                         0.273861   \n",
       "\n",
       "                                                       mean(min(test/recall))  \\\n",
       "dataset               model                                                     \n",
       "mnist_collage         abmil                                             0.068   \n",
       "                      discrete_rel_pos_self_attention                   0.216   \n",
       "                      distance_aware_self_attention                     0.216   \n",
       "                      gnn_gat                                           0.232   \n",
       "                      gnn_gcn                                           0.300   \n",
       "                      induced_set_transformer                           0.000   \n",
       "                      just_pool                                         0.332   \n",
       "                      mil_gnn                                           0.000   \n",
       "                      mil_gnn_ds                                        0.000   \n",
       "                      self_attention                                    0.052   \n",
       "                      self_attention_axial_pe                           0.124   \n",
       "                      self_attention_fourier_pe                         0.208   \n",
       "                      set_transformer                                   0.088   \n",
       "                      transmil                                          0.000   \n",
       "mnist_collage_inverse abmil                                             0.048   \n",
       "                      discrete_rel_pos_self_attention                   0.128   \n",
       "                      distance_aware_self_attention                     0.056   \n",
       "                      gnn_gat                                           0.020   \n",
       "                      gnn_gcn                                           0.060   \n",
       "                      induced_set_transformer                           0.000   \n",
       "                      just_pool                                         0.376   \n",
       "                      mil_gnn                                           0.000   \n",
       "                      mil_gnn_ds                                        0.000   \n",
       "                      self_attention                                    0.160   \n",
       "                      self_attention_axial_pe                           0.252   \n",
       "                      self_attention_fourier_pe                         0.156   \n",
       "                      set_transformer                                   0.000   \n",
       "                      transmil                                          0.040   \n",
       "\n",
       "                                                       std(min(test/recall))  \\\n",
       "dataset               model                                                    \n",
       "mnist_collage         abmil                                         0.052154   \n",
       "                      discrete_rel_pos_self_attention               0.235117   \n",
       "                      distance_aware_self_attention                 0.261687   \n",
       "                      gnn_gat                                       0.322676   \n",
       "                      gnn_gcn                                       0.311127   \n",
       "                      induced_set_transformer                       0.000000   \n",
       "                      just_pool                                     0.413183   \n",
       "                      mil_gnn                                       0.000000   \n",
       "                      mil_gnn_ds                                    0.000000   \n",
       "                      self_attention                                0.116276   \n",
       "                      self_attention_axial_pe                       0.117813   \n",
       "                      self_attention_fourier_pe                     0.247629   \n",
       "                      set_transformer                               0.196774   \n",
       "                      transmil                                      0.000000   \n",
       "mnist_collage_inverse abmil                                         0.107331   \n",
       "                      discrete_rel_pos_self_attention               0.100598   \n",
       "                      distance_aware_self_attention                 0.125220   \n",
       "                      gnn_gat                                       0.044721   \n",
       "                      gnn_gcn                                       0.123288   \n",
       "                      induced_set_transformer                       0.000000   \n",
       "                      just_pool                                     0.445960   \n",
       "                      mil_gnn                                       0.000000   \n",
       "                      mil_gnn_ds                                    0.000000   \n",
       "                      self_attention                                0.240416   \n",
       "                      self_attention_axial_pe                       0.245601   \n",
       "                      self_attention_fourier_pe                     0.184608   \n",
       "                      set_transformer                               0.000000   \n",
       "                      transmil                                      0.061644   \n",
       "\n",
       "                                                       mean(min(test/loss))  \\\n",
       "dataset               model                                                   \n",
       "mnist_collage         abmil                                        0.496041   \n",
       "                      discrete_rel_pos_self_attention              0.179238   \n",
       "                      distance_aware_self_attention                0.105759   \n",
       "                      gnn_gat                                      0.441132   \n",
       "                      gnn_gcn                                      0.429991   \n",
       "                      induced_set_transformer                      0.496567   \n",
       "                      just_pool                                    0.396384   \n",
       "                      mil_gnn                                      0.679137   \n",
       "                      mil_gnn_ds                                   0.577253   \n",
       "                      self_attention                               0.414764   \n",
       "                      self_attention_axial_pe                      0.453008   \n",
       "                      self_attention_fourier_pe                    0.364992   \n",
       "                      set_transformer                              0.380260   \n",
       "                      transmil                                     0.515279   \n",
       "mnist_collage_inverse abmil                                        0.492362   \n",
       "                      discrete_rel_pos_self_attention              0.288473   \n",
       "                      distance_aware_self_attention                0.201749   \n",
       "                      gnn_gat                                      0.495316   \n",
       "                      gnn_gcn                                      0.393801   \n",
       "                      induced_set_transformer                      0.501810   \n",
       "                      just_pool                                    0.479325   \n",
       "                      mil_gnn                                      0.674320   \n",
       "                      mil_gnn_ds                                   0.516723   \n",
       "                      self_attention                               0.453589   \n",
       "                      self_attention_axial_pe                      0.407073   \n",
       "                      self_attention_fourier_pe                    0.398939   \n",
       "                      set_transformer                              0.407280   \n",
       "                      transmil                                     0.503298   \n",
       "\n",
       "                                                       std(min(test/loss))  \\\n",
       "dataset               model                                                  \n",
       "mnist_collage         abmil                                       0.003200   \n",
       "                      discrete_rel_pos_self_attention             0.031020   \n",
       "                      distance_aware_self_attention               0.039776   \n",
       "                      gnn_gat                                     0.068110   \n",
       "                      gnn_gcn                                     0.063101   \n",
       "                      induced_set_transformer                     0.014609   \n",
       "                      just_pool                                   0.012937   \n",
       "                      mil_gnn                                     0.012082   \n",
       "                      mil_gnn_ds                                  0.095678   \n",
       "                      self_attention                              0.051002   \n",
       "                      self_attention_axial_pe                     0.087123   \n",
       "                      self_attention_fourier_pe                   0.049122   \n",
       "                      set_transformer                             0.075452   \n",
       "                      transmil                                    0.045246   \n",
       "mnist_collage_inverse abmil                                       0.002377   \n",
       "                      discrete_rel_pos_self_attention             0.120389   \n",
       "                      distance_aware_self_attention               0.141451   \n",
       "                      gnn_gat                                     0.009344   \n",
       "                      gnn_gcn                                     0.028638   \n",
       "                      induced_set_transformer                     0.007854   \n",
       "                      just_pool                                   0.013900   \n",
       "                      mil_gnn                                     0.032640   \n",
       "                      mil_gnn_ds                                  0.022650   \n",
       "                      self_attention                              0.037011   \n",
       "                      self_attention_axial_pe                     0.024743   \n",
       "                      self_attention_fourier_pe                   0.021093   \n",
       "                      set_transformer                             0.035888   \n",
       "                      transmil                                    0.046186   \n",
       "\n",
       "                                                       num_parameters  \n",
       "dataset               model                                            \n",
       "mnist_collage         abmil                                   16096.0  \n",
       "                      discrete_rel_pos_self_attention         17769.0  \n",
       "                      distance_aware_self_attention           17355.0  \n",
       "                      gnn_gat                                 16733.0  \n",
       "                      gnn_gcn                                 16303.0  \n",
       "                      induced_set_transformer                 22108.0  \n",
       "                      just_pool                               15585.0  \n",
       "                      mil_gnn                                 19198.0  \n",
       "                      mil_gnn_ds                              19198.0  \n",
       "                      self_attention                          17569.0  \n",
       "                      self_attention_axial_pe                 17569.0  \n",
       "                      self_attention_fourier_pe               18401.0  \n",
       "                      set_transformer                         17553.0  \n",
       "                      transmil                              2179281.0  \n",
       "mnist_collage_inverse abmil                                   16096.0  \n",
       "                      discrete_rel_pos_self_attention         17769.0  \n",
       "                      distance_aware_self_attention           17355.0  \n",
       "                      gnn_gat                                 16733.0  \n",
       "                      gnn_gcn                                 16303.0  \n",
       "                      induced_set_transformer                 22108.0  \n",
       "                      just_pool                               15585.0  \n",
       "                      mil_gnn                                 19198.0  \n",
       "                      mil_gnn_ds                              19198.0  \n",
       "                      self_attention                          17569.0  \n",
       "                      self_attention_axial_pe                 17569.0  \n",
       "                      self_attention_fourier_pe               18401.0  \n",
       "                      set_transformer                         17553.0  \n",
       "                      transmil                              2179281.0  \n",
       "\n",
       "[28 rows x 57 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mnist_collage = pd.DataFrame(mnist_collage_stats).T\n",
    "df_mnist_collage_inverse = pd.DataFrame(mnist_collage_inverse_stats).T\n",
    "\n",
    "# Merge\n",
    "df_mnist_collage[\"dataset\"] = \"mnist_collage\"\n",
    "df_mnist_collage_inverse[\"dataset\"] = \"mnist_collage_inverse\"\n",
    "df = pd.concat([df_mnist_collage, df_mnist_collage_inverse])\n",
    "df.index.name = \"model\"\n",
    "df.reset_index(inplace=True)\n",
    "df.set_index([\"dataset\", \"model\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{l|c|r|rr|rr}\n",
      "\\toprule\n",
      " & & & \\multicolumn{2}{c|}{\\smaller{MNIST-COLLAGE}} & \\multicolumn{2}{c}{\\smaller{MNIST-COLLAGE-INV}} \\\\\n",
      "Model & \\multicolumn{1}{c|}{Pos} & \\multicolumn{1}{c|}{Params} & \\multicolumn{1}{c}{Train} & \\multicolumn{1}{c|}{Test} & \\multicolumn{1}{c}{Train} & \\multicolumn{1}{c}{Test} \\\\\n",
      "\\midrule\n",
      "MIL with max pool & \\xmark & 15.6K & 0.846 $\\pm$ 0.021 & 0.828 $\\pm$ 0.033 & 0.840 $\\pm$ 0.009 & 0.788 $\\pm$ 0.029 \\\\\n",
      "AB-MIL~\\cite{ilse2018attention} & \\xmark & 16.1K & 0.799 $\\pm$ 0.014 & 0.740 $\\pm$ 0.010 & 0.805 $\\pm$ 0.006 & 0.692 $\\pm$ 0.015 \\\\\n",
      "MIL with GNN (GAT~\\cite{velickovic2018graph}) &  \\textsc{rel} & 16.7K & 0.811 $\\pm$ 0.089 & 0.758 $\\pm$ 0.041 & 0.745 $\\pm$ 0.033 & 0.716 $\\pm$ 0.018 \\\\\n",
      "MIL with GNN (GCN~\\cite{kipf2017semisupervised}) &  \\textsc{rel} & 16.3K & 0.865 $\\pm$ 0.031 & 0.790 $\\pm$ 0.058 & 0.883 $\\pm$ 0.034 & 0.794 $\\pm$ 0.036 \\\\\n",
      "MIL with iSet Transformer~\\cite{lee2019set} & \\xmark & 22.1K & 0.813 $\\pm$ 0.017 & 0.734 $\\pm$ 0.040 & 0.813 $\\pm$ 0.023 & 0.720 $\\pm$ 0.016 \\\\\n",
      "MIL with Set Transformer~\\cite{lee2019set} & \\xmark & 17.6K & 0.815 $\\pm$ 0.052 & 0.832 $\\pm$ 0.041 & 0.819 $\\pm$ 0.018 & 0.792 $\\pm$ 0.045 \\\\\n",
      "MIL-GNN~\\cite{tu2019multiple} &  \\textsc{rel} & 19.2K & 0.546 $\\pm$ 0.061 & 0.578 $\\pm$ 0.084 & 0.543 $\\pm$ 0.095 & 0.542 $\\pm$ 0.094 \\\\\n",
      "MIL-GNN-DS~\\cite{tu2019multiple} &  \\textsc{rel} & 19.2K & 0.686 $\\pm$ 0.143 & 0.656 $\\pm$ 0.123 & 0.784 $\\pm$ 0.023 & 0.756 $\\pm$ 0.019 \\\\\n",
      "MIL with SA~\\cite{vaswani2017attention} & \\xmark & 17.6K & 0.882 $\\pm$ 0.041 & 0.786 $\\pm$ 0.035 & 0.876 $\\pm$ 0.059 & 0.764 $\\pm$ 0.035 \\\\\n",
      "MIL with SA + axial PE~\\cite{ramachandran2019stand} &  \\textsc{abs} & 17.6K & 0.862 $\\pm$ 0.008 & 0.786 $\\pm$ 0.051 & 0.902 $\\pm$ 0.018 & 0.774 $\\pm$ 0.015 \\\\\n",
      "MIL with SA + Fourier PE~\\cite{yang2021learnable} &  \\textsc{abs} & 18.4K & 0.878 $\\pm$ 0.035 & 0.820 $\\pm$ 0.022 & 0.879 $\\pm$ 0.037 & 0.808 $\\pm$ 0.029 \\\\\n",
      "MIL with disc.\\ rel.\\ SA~\\cite{wu2021rethinking} &  \\textsc{rel} & 17.8K & 0.921 $\\pm$ 0.014 & 0.926 $\\pm$ 0.030 & 0.877 $\\pm$ 0.031 & 0.846 $\\pm$ 0.060 \\\\\n",
      "Trans-MIL~\\cite{shao2021transmil} &  \\textsc{abs} & 2.18M & \\textbf{0.957 $\\pm$ 0.029} & 0.728 $\\pm$ 0.054 & \\textbf{0.957 $\\pm$ 0.015} & 0.742 $\\pm$ 0.053 \\\\\n",
      "DAS-MIL (ours) &  \\textsc{rel} & 17.4K & 0.932 $\\pm$ 0.029 & \\textbf{0.942 $\\pm$ 0.013} & 0.910 $\\pm$ 0.048 & \\textbf{0.898 $\\pm$ 0.071} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "NAMES = {\n",
    "    \"just_pool\": \"MIL with max pool\",\n",
    "    \"abmil\": \"AB-MIL~\\\\cite{ilse2018attention}\",\n",
    "    \"gnn_gat\": \"MIL with GNN (GAT~\\\\cite{velickovic2018graph})\",\n",
    "    \"gnn_gcn\": \"MIL with GNN (GCN~\\\\cite{kipf2017semisupervised})\",\n",
    "    \"induced_set_transformer\": \"MIL with iSet Transformer~\\\\cite{lee2019set}\",\n",
    "    \"set_transformer\": \"MIL with Set Transformer~\\\\cite{lee2019set}\",\n",
    "    \"mil_gnn\": \"MIL-GNN~\\\\cite{tu2019multiple}\",\n",
    "    \"mil_gnn_ds\": \"MIL-GNN-DS~\\\\cite{tu2019multiple}\",\n",
    "    \"self_attention\": \"MIL with SA~\\\\cite{vaswani2017attention}\",\n",
    "    \"self_attention_axial_pe\": \"MIL with SA + axial PE~\\\\cite{ramachandran2019stand}\",\n",
    "    \"self_attention_fourier_pe\": \"MIL with SA + Fourier PE~\\\\cite{yang2021learnable}\",\n",
    "    \"discrete_rel_pos_self_attention\": \"MIL with disc.\\\\ rel.\\\\ SA~\\\\cite{wu2021rethinking}\",\n",
    "    \"transmil\": \"Trans-MIL~\\\\cite{shao2021transmil}\",\n",
    "    \"distance_aware_self_attention\": \"DAS-MIL (ours)\",\n",
    "}\n",
    "abs_pos = [\"self_attention_axial_pe\", \"self_attention_fourier_pe\", \"transmil\"]\n",
    "rel_pos = [\"discrete_rel_pos_self_attention\", \"distance_aware_self_attention\", \"mil_gnn\", \"mil_gnn_ds\", \"gnn_gat\", \"gnn_gcn\"]\n",
    "\n",
    "   \n",
    "\n",
    "print(\"\\\\begin{tabular}{l|c|r|rr|rr}\")\n",
    "print(\"\\\\toprule\")\n",
    "print(\" & & & \\\\multicolumn{2}{c|}{\\\\smaller{MNIST-COLLAGE}} & \\\\multicolumn{2}{c}{\\\\smaller{MNIST-COLLAGE-INV}} \\\\\\\\\")\n",
    "print(\"Model & \\\\multicolumn{1}{c|}{Pos} & \\\\multicolumn{1}{c|}{Params} & \\\\multicolumn{1}{c}{Train} & \\\\multicolumn{1}{c|}{Test} & \\\\multicolumn{1}{c}{Train} & \\\\multicolumn{1}{c}{Test} \\\\\\\\\")\n",
    "print(\"\\\\midrule\")\n",
    "\n",
    "rows = {name: row for name, row in df.iterrows()}\n",
    "for name, desc in NAMES.items():\n",
    "    pos = \"abs\" if name in abs_pos else \"rel\" if name in rel_pos else None\n",
    "    row = f\"{NAMES[name]}\"\n",
    "    pos = f\" \\\\textsc{{{pos}}}\" if pos in (\"abs\", \"rel\") else \"\\\\xmark\"\n",
    "    row += f\" & {pos}\"\n",
    "    row += f\" & {human_format(df.loc['mnist_collage', name]['num_parameters'])}\"\n",
    "\n",
    "    metric = \"balanced_acc\"\n",
    "\n",
    "    for dataset in (\"mnist_collage\", \"mnist_collage_inverse\"):\n",
    "        df_ds = df.loc[dataset]\n",
    "        for split in (\"train\", \"test\"):\n",
    "            if df_ds[f\"mean({split}/{metric})\"].max() == df_ds[f\"mean({split}/{metric})\"].loc[name]:\n",
    "                row += f\" & \\\\textbf{{{df_ds[f'mean({split}/{metric})'].loc[name]:.03f} $\\pm$ {df_ds[f'std({split}/{metric})'].loc[name]:.03f}}}\"\n",
    "            else:\n",
    "                row += f\" & {df_ds[f'mean({split}/{metric})'].loc[name]:.03f} $\\pm$ {df_ds[f'std({split}/{metric})'].loc[name]:.03f}\"\n",
    "    print(row + \" \\\\\\\\\")\n",
    "print(\"\\\\bottomrule\")\n",
    "print(\"\\\\end{tabular}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mil_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
